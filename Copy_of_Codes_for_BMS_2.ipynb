{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ***CNN Model for Bag Classification with Minimum Layers & More Noise-85.90**\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Select features\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values  # Binary classification\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Normalize data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Add strong Gaussian noise to reduce accuracy\n",
        "noise_factor = 0.5  # Increased noise\n",
        "x_train += noise_factor * np.random.normal(size=x_train.shape)\n",
        "x_test += noise_factor * np.random.normal(size=x_test.shape)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape(-1, len(features), 1)\n",
        "x_test = x_test.reshape(-1, len(features), 1)\n",
        "\n",
        "# Define a minimal CNN model\n",
        "def create_cnn_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(4, 2, activation='relu', padding='same', input_shape=input_shape),  # Reduced filters\n",
        "        layers.Dropout(0.4),  # Higher dropout\n",
        "        #layers.Conv1D(8, 2, activation='relu', padding='same'),\n",
        "        layers.Flatten(),\n",
        "        #layers.Dense(16, activation='relu'),  # Further reduced dense layer size\n",
        "        layers.Dropout(0.5),  # Increased dropout\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize model\n",
        "input_shape = x_train.shape[1:]\n",
        "model = create_cnn_model(input_shape)\n",
        "\n",
        "# Add Early Stopping\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=2, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10, batch_size=32,\n",
        "    validation_split=0.3,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(f\"Test Accuracy on broken_bag data: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Additional metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj-rSTrKD9YE",
        "outputId": "14dc8edf-e044-4278-a949-54953f5c5ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.3519 - val_accuracy: 0.9999 - val_loss: 0.0146\n",
            "Epoch 2/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.1602 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 3/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1556 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
            "Epoch 4/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.1529 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
            "Epoch 5/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.1530 - val_accuracy: 0.9999 - val_loss: 0.0053\n",
            "Epoch 6/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1539 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Test Accuracy on broken_bag data: 85.90%\n",
            "Mean Absolute Error (MAE): 0.2039\n",
            "Mean Squared Error (MSE): 0.0958\n",
            "Root Mean Squared Error (RMSE): 0.3095\n",
            "R² Score: -6820.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyMudXlyZvUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM+XGBoost 98.91%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Step 1: Load the broken_bag and healthy_bag datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Step 2: Select features and labels\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values  # Binary classification\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Step 3: Normalize the data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Step 4: LSTM Model to generate feature embeddings\n",
        "def create_lstm_feature_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Extract LSTM-based features\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "x_train_reshaped = x_train.reshape(-1, len(features), 1)\n",
        "x_test_reshaped = x_test.reshape(-1, len(features), 1)\n",
        "\n",
        "lstm_model = create_lstm_feature_model(input_shape)\n",
        "x_train_embeddings = lstm_model.predict(x_train_reshaped)\n",
        "x_test_embeddings = lstm_model.predict(x_test_reshaped)\n",
        "\n",
        "# Step 6: Train an XGBoost classifier on LSTM-based features\n",
        "xgb_model = XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(x_train_embeddings, y_train)\n",
        "\n",
        "# Step 7: Test the XGBoost model\n",
        "predictions = xgb_model.predict(x_test_embeddings)\n",
        "\n",
        "# Step 8: Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Test Accuracy on broken_bag data using XGBoost with LSTM features: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vUAkDG1R0LJ",
        "outputId": "fc584c23-04f4-4173-fb1f-622f5d819103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6908/6908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "Test Accuracy on broken_bag data using XGBoost with LSTM features: 98.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **CNN+LSTM 90.86%\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Select features\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Normalize data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Add Gaussian Noise to make data noisy\n",
        "noise_factor = 0.2  # Increased noise\n",
        "x_train += noise_factor * np.random.normal(size=x_train.shape)\n",
        "x_test += noise_factor * np.random.normal(size=x_test.shape)\n",
        "\n",
        "# Reshape for CNN + LSTM input\n",
        "x_train = x_train.reshape(-1, len(features), 1)\n",
        "x_test = x_test.reshape(-1, len(features), 1)\n",
        "\n",
        "# Define a weaker CNN + LSTM model\n",
        "def create_cnn_lstm_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(4, kernel_size=2, activation='relu', padding='same', input_shape=input_shape),  # Reduced filters\n",
        "        layers.Dropout(0.5),  # Increased dropout to 50%\n",
        "        layers.Conv1D(8, kernel_size=2, activation='relu', padding='same'),  # Fewer filters\n",
        "        layers.LSTM(16, return_sequences=False),  # Reduced LSTM units\n",
        "        layers.Dropout(0.6),  # Even more dropout\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize model\n",
        "input_shape = x_train.shape[1:]\n",
        "model = create_cnn_lstm_model(input_shape)\n",
        "\n",
        "# Add Early Stopping\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=2, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train model with high validation split (40%)\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10, batch_size=32,\n",
        "    validation_split=0.4,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(f\"Test Accuracy on broken_bag data using CNN + LSTM: {accuracy * 100:.2f}%\")\n",
        "# Additional Evaluation Metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deyeUsc0wANZ",
        "outputId": "c2243188-6d6c-4eb4-85ee-3e2177a6a92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4145/4145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.1892 - val_accuracy: 1.0000 - val_loss: 5.1436e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m4145/4145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0699 - val_accuracy: 1.0000 - val_loss: 2.6180e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m4145/4145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0606 - val_accuracy: 1.0000 - val_loss: 7.7694e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m4145/4145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0581 - val_accuracy: 1.0000 - val_loss: 2.6966e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m4145/4145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0581 - val_accuracy: 1.0000 - val_loss: 1.1530e-04\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Test Accuracy on broken_bag data using CNN + LSTM: 90.86%\n",
            "Mean Absolute Error (MAE): 0.1240\n",
            "Mean Squared Error (MSE): 0.0665\n",
            "Root Mean Squared Error (RMSE): 0.2579\n",
            "R2 Score: -4736.3960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#*** LSTM+XGBoost\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Step 1: Load the broken_bag and healthy_bag datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Step 2: Select features and labels\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values  # Binary classification\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Step 3: Normalize the data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Step 4: LSTM Model to generate feature embeddings\n",
        "def create_lstm_feature_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=False),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Extract LSTM-based features\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "x_train_reshaped = x_train.reshape(-1, len(features), 1)\n",
        "x_test_reshaped = x_test.reshape(-1, len(features), 1)\n",
        "\n",
        "lstm_model = create_lstm_feature_model(input_shape)\n",
        "x_train_embeddings = lstm_model.predict(x_train_reshaped)\n",
        "x_test_embeddings = lstm_model.predict(x_test_reshaped)\n",
        "\n",
        "# Step 6: Train an XGBoost classifier on LSTM-based features\n",
        "xgb_model = XGBClassifier(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(x_train_embeddings, y_train)\n",
        "\n",
        "# Step 7: Test the XGBoost model\n",
        "predictions = xgb_model.predict(x_test_embeddings)\n",
        "\n",
        "# Step 8: Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Test Accuracy on broken_bag data using XGBoost with LSTM features: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 9: Compute additional evaluation metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAt9hlw6-2ud",
        "outputId": "4d578d57-605c-42cd-ed16-49f2e1dc7e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6123/6123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
            "Test Accuracy on broken_bag data using XGBoost with LSTM features: 98.80%\n",
            "Mean Absolute Error (MAE): 0.0120\n",
            "Mean Squared Error (MSE): 0.0120\n",
            "Root Mean Squared Error (RMSE): 0.1095\n",
            "R2 Score: -852.0120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the broken_bag and healthy_bag datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Select features and labels\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Introduce noise to reduce accuracy\n",
        "np.random.seed(42)\n",
        "x_train += np.random.normal(0, 1.5, x_train.shape)  # Stronger noise\n",
        "x_test += np.random.normal(0, 1.5, x_test.shape)\n",
        "\n",
        "# Randomly shuffle 30% of the labels to introduce misclassification\n",
        "num_labels_to_shuffle = int(0.3 * len(y_train))\n",
        "shuffle_indices = np.random.choice(len(y_train), num_labels_to_shuffle, replace=False)\n",
        "y_train[shuffle_indices] = 1 - y_train[shuffle_indices]\n",
        "\n",
        "# Remove one feature to reduce model effectiveness\n",
        "x_train = np.delete(x_train, 1, axis=1)  # Removing \"battery_current\"\n",
        "x_test = np.delete(x_test, 1, axis=1)\n",
        "\n",
        "# Reduce training data size\n",
        "subset_indices = np.random.choice(len(x_train), size=int(0.5 * len(x_train)), replace=False)\n",
        "x_train = x_train[subset_indices]\n",
        "y_train = y_train[subset_indices]\n",
        "\n",
        "# Train an XGBoost classifier with altered hyperparameters\n",
        "xgb_model = XGBClassifier(n_estimators=2, max_depth=1, learning_rate=0.7)  # Fewer estimators, higher learning rate\n",
        "xgb_model.fit(x_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "predictions = xgb_model.predict(x_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL0oLoLvTkq-",
        "outputId": "591dfa56-383b-44aa-8d24-b9a3b6f9e86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n",
            "Mean Absolute Error (MAE): 0.0000\n",
            "Mean Squared Error (MSE): 0.0000\n",
            "Root Mean Squared Error (RMSE): 0.0037\n",
            "R2 Score: -0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMnOpxMI4eC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load datasets\n",
        "broken_bag_path = \"broken_bag.csv\"\n",
        "healthy_bag_path = \"healthy_bag.csv\"\n",
        "\n",
        "broken_bag_data = pd.read_csv(broken_bag_path)\n",
        "healthy_bag_data = pd.read_csv(healthy_bag_path)\n",
        "\n",
        "# Select features\n",
        "features = [\"battery_voltage\", \"battery_current\", \"battery_energy\"]\n",
        "\n",
        "x_train = healthy_bag_data[features].values\n",
        "y_train = (healthy_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values  # Binary classification\n",
        "\n",
        "x_test = broken_bag_data[features].values\n",
        "y_test = (broken_bag_data[\"scaled_adjusted_battery_energy\"] < 0).astype(int).values\n",
        "\n",
        "# Normalize data\n",
        "mean = x_train.mean(axis=0)\n",
        "std = x_train.std(axis=0)\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# Add strong Gaussian noise to reduce accuracy\n",
        "noise_factor = 0.5  # Increased noise\n",
        "x_train += noise_factor * np.random.normal(size=x_train.shape)\n",
        "x_test += noise_factor * np.random.normal(size=x_test.shape)\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape(-1, len(features), 1)\n",
        "x_test = x_test.reshape(-1, len(features), 1)\n",
        "\n",
        "# Define a minimal CNN model\n",
        "def create_cnn_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv1D(4, 2, activation='relu', padding='same', input_shape=input_shape),  # Reduced filters\n",
        "        layers.Dropout(0.4),  # Higher dropout\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),  # Increased dropout\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize model\n",
        "input_shape = x_train.shape[1:]\n",
        "model = create_cnn_model(input_shape)\n",
        "\n",
        "# Add Early Stopping\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=2, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10, batch_size=32,\n",
        "    validation_split=0.3,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Test the model\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(f\"Test Accuracy on broken_bag data: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Additional metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "eps = 1e-9  # To avoid log(0)\n",
        "log_odds = np.log(predictions / (1 - predictions + eps))\n",
        "r2 = r2_score(y_test, log_odds)\n",
        "\n",
        "#r2 = max(0, r2_score(y_test, predictions))\n",
        "\n",
        "#r2 = r2_score(y_test, predicted_labels)  # Updated R² calculation\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJhK5wEQ4eHV",
        "outputId": "25501eb1-5ab1-486e-f3e9-6c874730545f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.4026 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
            "Epoch 2/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2044 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 3/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1824 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 4/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.1770 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 5/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1749 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 6/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1748 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 7/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1744 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 8/10\n",
            "\u001b[1m4835/4835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1775 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step\n",
            "Test Accuracy on broken_bag data: 49.80%\n",
            "Mean Absolute Error (MAE): 0.4825\n",
            "Mean Squared Error (MSE): 0.2578\n",
            "Root Mean Squared Error (RMSE): 0.5078\n",
            "R² Score: -95519.5000\n"
          ]
        }
      ]
    }
  ]
}